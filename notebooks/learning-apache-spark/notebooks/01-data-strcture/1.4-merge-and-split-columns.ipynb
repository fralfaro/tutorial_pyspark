{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fralfaro/tutorial_pyspark/blob/main/notebooks/learning-apache-spark/notebooks/01-data-strcture/1.4-merge-and-split-columns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WK7B1PxHdSl8",
        "outputId": "8dc4c6b6-c247-4b87-b507-9cdf1a9c2148",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=234aae1c7a0859116b3eb8a41de6f1b84bdcbbd47a693e216ce8971d2e3ecf75\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# files\n",
        "!wget https://raw.githubusercontent.com/fralfaro/tutorial_pyspark/main/notebooks/learning-apache-spark/data/mtcars.csv"
      ],
      "metadata": {
        "id": "60AOpjeedVJk",
        "outputId": "4f68ecf4-7055-4923-ef82-445dabcd0a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-19 20:14:30--  https://raw.githubusercontent.com/fralfaro/tutorial_pyspark/main/notebooks/learning-apache-spark/data/mtcars.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1694 (1.7K) [text/plain]\n",
            "Saving to: ‘mtcars.csv’\n",
            "\n",
            "\rmtcars.csv            0%[                    ]       0  --.-KB/s               \rmtcars.csv          100%[===================>]   1.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-19 20:14:31 (32.9 MB/s) - ‘mtcars.csv’ saved [1694/1694]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "sc=SparkContext()\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "metadata": {
        "id": "948HSfNgdVTO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOmh7o2TdSl_"
      },
      "source": [
        "## Merge and split columns\n",
        "\n",
        "Sometimes we need to merge multiple columns in a Dataframe into one column, or split a column into multiple columns. We can easily achieve this by converting a DataFrame to RDD, applying map functions to manipulate elements, and then converting the RDD back to a DataFrame.\n",
        "\n",
        "### Example data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tLUegVAIdSmA"
      },
      "outputs": [],
      "source": [
        "mtcars = spark.read.csv(path='mtcars.csv',\n",
        "                        sep=',',\n",
        "                        encoding='UTF-8',\n",
        "                        comment=None,\n",
        "                        header=True, \n",
        "                        inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q2SyzCgCdSmB",
        "outputId": "be61870f-c342-45c7-f5e1-856b1172d918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|              _c0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtcars.show(n=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PaTDjJs3dSmB",
        "outputId": "6db1cad4-4638-4196-ab1b-271b8c5641c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|            model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# adjust first column name\n",
        "colnames = mtcars.columns\n",
        "colnames[0] = 'model'\n",
        "mtcars = mtcars.rdd.toDF(colnames)\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo7jtjLUdSmC"
      },
      "source": [
        "### Merge multiple columns\n",
        "\n",
        "We convert DataFrame to RDD and then apply the **map** function to merge values and convert \n",
        "elements to **Row** objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7Bf4Ll1NdSmC",
        "outputId": "54e9b0b4-b70f-4759-f21c-6eb1ce17920f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(model='Mazda RX4', values=(21.0, 6, 160.0, 110, 3.9, 2.62, 16.46, 0, 1, 4, 4)),\n",
              " Row(model='Mazda RX4 Wag', values=(21.0, 6, 160.0, 110, 3.9, 2.875, 17.02, 0, 1, 4, 4)),\n",
              " Row(model='Datsun 710', values=(22.8, 4, 108.0, 93, 3.85, 2.32, 18.61, 1, 1, 4, 1)),\n",
              " Row(model='Hornet 4 Drive', values=(21.4, 6, 258.0, 110, 3.08, 3.215, 19.44, 1, 0, 3, 1)),\n",
              " Row(model='Hornet Sportabout', values=(18.7, 8, 360.0, 175, 3.15, 3.44, 17.02, 0, 0, 3, 2))]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from pyspark.sql import Row\n",
        "mtcars_rdd = mtcars.rdd.map(lambda x: Row(model=x[0], values=x[1:]))\n",
        "mtcars_rdd.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2iqeYWmdSmD"
      },
      "source": [
        "Then we create a new DataFrame from the obtained RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fK9sCZ-tdSmE",
        "outputId": "18b8a4d8-14c3-4b22-a51f-0ddc2613ad6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------------------------------------------+\n",
            "|model            |values                                               |\n",
            "+-----------------+-----------------------------------------------------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9, 2.62, 16.46, 0, 1, 4, 4}  |\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9, 2.875, 17.02, 0, 1, 4, 4} |\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85, 2.32, 18.61, 1, 1, 4, 1}  |\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08, 3.215, 19.44, 1, 0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15, 3.44, 17.02, 0, 0, 3, 2} |\n",
            "+-----------------+-----------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtcars_df = spark.createDataFrame(mtcars_rdd)\n",
        "mtcars_df.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Cw-SpCdSmE"
      },
      "source": [
        "## Split one column\n",
        "\n",
        "We use the above DataFrame as our example data. Again, we need to convert the DataFrame to an RDD to achieve our goal.\n",
        "\n",
        "Let's split the **values** column into two columns: x1 and x2. The first 4 values will be in column **x1** and the remaining values will be in column **x2**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fPlHPRXpdSmF",
        "outputId": "d4f599d1-eaa2-4d68-d4bb-b3be90a4c1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------------------------+--------------------------+\n",
            "|model            |x1                         |x2                        |\n",
            "+-----------------+---------------------------+--------------------------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9} |{2.62, 16.46, 0, 1, 4, 4} |\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9} |{2.875, 17.02, 0, 1, 4, 4}|\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85} |{2.32, 18.61, 1, 1, 4, 1} |\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08}|{3.215, 19.44, 1, 0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15}|{3.44, 17.02, 0, 0, 3, 2} |\n",
            "+-----------------+---------------------------+--------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mtcars_rdd_2 = mtcars_df.rdd.map(lambda x: Row(model=x[0], x1=x[1][:5], x2=x[1][5:]))\n",
        "# convert RDD back to DataFrame\n",
        "mtcars_df_2 = spark.createDataFrame(mtcars_rdd_2)\n",
        "mtcars_df_2.show(5, truncate=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "1.4-merge-and-split-columns.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}